{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": " TweetSentiment.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "mount_file_id": "15XPV3-4KZvL9w7HZ4aDWtY-T__JxHTdt",
      "authorship_tag": "ABX9TyN95IEmOzq40zn49w6lO719",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/birajsilwal/TweetSentiment/blob/master/TweetSentiment.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lxdxVZdGln9U"
      },
      "source": [
        "import re"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b2sqo5nG5brz"
      },
      "source": [
        "# Filter tweets class"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ntir5YuYoR5u"
      },
      "source": [
        "\n",
        "'''\n",
        "this class filters (removes tweet tags, punctuations,\n",
        "irrelevant words such as a, an, the) from the tweets\n",
        "and returns array of clean filtered tweets\n",
        "'''\n",
        "class FilterTweets:\n",
        "\n",
        "    \n",
        "    def filterTweets(self, file_path):\n",
        "      final_tweets = []\n",
        "      tweets = []\n",
        "      tweets_raw = open(file_path)\n",
        "      for tweet in tweets_raw:\n",
        "          tweet = tweet.lower()\n",
        "          tweet = re.sub(\":|;|\\(|\\)|!|\\'s|\\\"|\\.|n\\'t|,|\\?|i\\'m|i\\'ve\", \"\", tweet)\n",
        "          tweet = re.sub(\" an | the | is | of | a | i | was | and |\"\n",
        "                          \" on | in | off | all | it | me | you | to |\"\n",
        "                          \" into | we | your | that | they | can | could |\"\n",
        "                          \" should | do | does | for | my | at | so |\"\n",
        "                          \" if | has | have | had | from | such | are |\"\n",
        "                          \" not | this | now | but | go | day |\"\n",
        "                          \"-|_| up | down | these | today | lol |\"\n",
        "                          \" lmao | af | get | got | here | there | who |\"\n",
        "                          \" what | am | no | why | with | us | our | bro |\"\n",
        "                          \" too | then | ur | zero | ah | see | saw \", \" \", tweet)\n",
        "          tweets.append(tweet)\n",
        "\n",
        "\n",
        "      # cleaning up twice because of space issue\n",
        "      tweets1 = []\n",
        "      for tweet in tweets:\n",
        "          tweet = tweet.lower()\n",
        "          tweet = re.sub(\" an | the | is | of | a | i | was | and |\"\n",
        "                          \" on | in | off | all | it | me | you | to |\"\n",
        "                          \" into | we | your | that | they | can | could |\"\n",
        "                          \" should | do | does | for | my | at | so |\"\n",
        "                          \" if | has | have | had | from | such | are |\"\n",
        "                          \" not | this | now | but | go | day |\"\n",
        "                          \"-|_| up | down | these | today | lol |\"\n",
        "                          \" lmao | af | get | got | here | there | who |\"\n",
        "                          \" what | am | no | why | with | us | our | bro |\"\n",
        "                          \" too | then | ur | zero | ah | see | saw \", \" \", tweet)\n",
        "          tweets1.append(tweet)\n",
        "\n",
        "\n",
        "      '''\n",
        "      if there contains a substring starting with http or @,\n",
        "      remove that substring from the tweet\n",
        "      '''\n",
        "      for str in tweets1:\n",
        "          index = 0\n",
        "          string_arr = str.split()\n",
        "          for string in string_arr:\n",
        "              if 'http' in string or '@' in string:\n",
        "                  string_arr[index] = string.replace(string, '')\n",
        "              index += 1\n",
        "\n",
        "          tweet = ' '\n",
        "          tweet = tweet.join(string_arr)\n",
        "          final_tweets.append(tweet)\n",
        "          # print(tweet)\n",
        "      return final_tweets"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XpNCTjW88VRG"
      },
      "source": [
        "# Filtered datasets"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uB3h2aVGomL7",
        "outputId": "ba10bc4e-1e77-4b47-ccd6-96cf5fa30d73"
      },
      "source": [
        "filter_tweets = FilterTweets()\n",
        "\n",
        "tweets_training_filtered = filter_tweets.filterTweets('/content/drive/MyDrive/Colab Notebooks/Tweets/noCR_train.txt')\n",
        "print(len(tweets_training_filtered))\n",
        "\n",
        "tweets_testing_filtered = filter_tweets.filterTweets('/content/drive/MyDrive/Colab Notebooks/Tweets/noCR_test.txt')\n",
        "print(len(tweets_testing_filtered))"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "10271\n",
            "1145\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IZGIgdr-OLOD"
      },
      "source": [
        ""
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Q11axTfSJw5A"
      },
      "source": [
        "# Tweet class"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kWdGnFjIHBhX"
      },
      "source": [
        "class Tweet:\n",
        "  def __init__(self, tweet, zero_or_one):\n",
        "      self.tweet = tweet\n",
        "      self.zero_or_one = zero_or_one\n",
        "      self.sentiment = self.get_sentiment()\n",
        "\n",
        "  \n",
        "  def get_sentiment(self):\n",
        "    if self.zero_or_one == '0':\n",
        "      return \"NEGATIVE\"\n",
        "    elif self.zero_or_one == '1':\n",
        "      return \"POSITIVE\" \n"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hhrtZpLRIrLV"
      },
      "source": [
        "# creating tweet objects for each tweet\n",
        "tweets_training = []\n",
        "tweets_testing = []\n",
        "\n",
        "for tweet in tweets_training_filtered:\n",
        "  string_arr = tweet.split()\n",
        "  zero_or_one = string_arr.pop(0)\n",
        "\n",
        "  tweet1 = ' '\n",
        "  tweet1 = tweet1.join(string_arr)\n",
        "  tweets_training.append(Tweet(tweet1, zero_or_one))\n",
        "\n",
        "\n",
        "for tweet in tweets_testing_filtered:\n",
        "  string_arr = tweet.split()\n",
        "  zero_or_one = string_arr.pop(0)\n",
        "\n",
        "  tweet1 = ' '\n",
        "  tweet1 = tweet1.join(string_arr)\n",
        "  tweets_testing.append(Tweet(tweet1, zero_or_one))"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mCK6E_bEYy25"
      },
      "source": [
        "# x and y values for both training and testing dataset\n",
        "train_x = [x.tweet for x in tweets_training]\n",
        "train_y = [x.sentiment for x in tweets_training]\n",
        "\n",
        "test_x = [x.tweet for x in tweets_testing]\n",
        "test_y = [x.sentiment for x in tweets_testing]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kv8UhTIAZZLH"
      },
      "source": [
        "# Python dictionary"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qVWi9rMtZfQP",
        "outputId": "379e7eb8-3b5b-4f71-ce5b-2f08c02fffdb"
      },
      "source": [
        "dict_tweet = {}\n",
        "val = 1\n",
        "\n",
        "for tweet in train_x:\n",
        "    tweet_arr = tweet.split()\n",
        "\n",
        "    for x in range(len(tweet_arr)):\n",
        "        key = tweet_arr[x]\n",
        "        '''\n",
        "        see if the key already exists in the dictionary\n",
        "        if yes, increase the value by 1 otherwise\n",
        "        new key and val.\n",
        "        '''\n",
        "        if key in dict_tweet:\n",
        "            update_val = dict_tweet[key] + 1\n",
        "            update_dict = {key: update_val}\n",
        "            dict_tweet.update(update_dict)\n",
        "        else:\n",
        "            dict_tweet[key] = val"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "12664\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "m0bIxtDmX3UZ"
      },
      "source": [
        "# Vectorization"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kHSCDS_SX86y"
      },
      "source": [
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "import numpy as np\n",
        "\n",
        "vectorizer = CountVectorizer()\n",
        "\n",
        "train_x_vectors = vectorizer.fit_transform(train_x)\n"
      ],
      "execution_count": 7,
      "outputs": []
    }
  ]
}