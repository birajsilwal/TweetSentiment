{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": " TweetSentiment.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyN4LLl9Vcu1GUB1wfaICSEW",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/birajsilwal/TweetSentiment/blob/master/TweetSentiment.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lxdxVZdGln9U"
      },
      "source": [
        "import re"
      ],
      "execution_count": 40,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b2sqo5nG5brz"
      },
      "source": [
        "# Filtering tweets"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZoXhjXzV5guH"
      },
      "source": [
        ""
      ],
      "execution_count": 40,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ntir5YuYoR5u"
      },
      "source": [
        "\n",
        "'''\n",
        "this class filters (removes tweet tags, punctuations,\n",
        "irrelevant words such as a, an, the) from the tweets\n",
        "and returns array of clean filtered tweets\n",
        "'''\n",
        "class FilterTweets:\n",
        "    # opening the testing file\n",
        "    \n",
        "    def filterTweets(self, file_path):\n",
        "      final_tweets = []\n",
        "      tweets = []\n",
        "      tweets_raw = open(file_path)\n",
        "      for tweet in tweets_raw:\n",
        "          tweet = tweet.lower()\n",
        "          tweet = re.sub(\":|;|\\(|\\)|!|\\'s|\\\"|\\.|n\\'t|,|\\?|i\\'m|i\\'ve\", \"\", tweet)\n",
        "          tweet = re.sub(\" an | the | is | of | a | i | was | and |\"\n",
        "                          \" on | in | off | all | it | me | you | to |\"\n",
        "                          \" into | we | your | that | they | can | could |\"\n",
        "                          \" should | do | does | for | my | at | so |\"\n",
        "                          \" if | has | have | had | from | such | are |\"\n",
        "                          \" not | this | now | but | go | day |\"\n",
        "                          \"-|_| up | down | these | today | lol |\"\n",
        "                          \" lmao | af | get | got | here | there | who |\"\n",
        "                          \" what | am | no | why | with | us | our | bro |\"\n",
        "                          \" too | then | ur | zero | ah | see | saw \", \" \", tweet)\n",
        "          tweets.append(tweet)\n",
        "\n",
        "\n",
        "      # cleaning up twice because of space issue\n",
        "      tweets1 = []\n",
        "      for tweet in tweets:\n",
        "          tweet = tweet.lower()\n",
        "          tweet = re.sub(\" an | the | is | of | a | i | was | and |\"\n",
        "                          \" on | in | off | all | it | me | you | to |\"\n",
        "                          \" into | we | your | that | they | can | could |\"\n",
        "                          \" should | do | does | for | my | at | so |\"\n",
        "                          \" if | has | have | had | from | such | are |\"\n",
        "                          \" not | this | now | but | go | day |\"\n",
        "                          \" - | up | down | these | today | lol |\"\n",
        "                          \" lmao | af | get | got | here | there | who |\"\n",
        "                          \" what | am | no | why | with | us | our | bro \", \" \", tweet)\n",
        "          tweets1.append(tweet)\n",
        "\n",
        "\n",
        "      '''\n",
        "      if there contains a substring starting with http or @,\n",
        "      remove that substring from the tweet\n",
        "      '''\n",
        "      for str in tweets1:\n",
        "          index = 0\n",
        "          string_arr = str.split()\n",
        "          for string in string_arr:\n",
        "              if 'http' in string or '@' in string:\n",
        "                  string_arr[index] = string.replace(string, '')\n",
        "              index += 1\n",
        "\n",
        "          tweet = ' '\n",
        "          tweet = tweet.join(string_arr)\n",
        "          final_tweets.append(tweet)\n",
        "          # print(tweet)\n",
        "      return final_tweets"
      ],
      "execution_count": 45,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XpNCTjW88VRG"
      },
      "source": [
        "# Testing and Training datasets"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uB3h2aVGomL7",
        "outputId": "3c048e28-3110-4540-f49f-ad6f75776b69"
      },
      "source": [
        "filter_tweets = FilterTweets()\n",
        "\n",
        "tweets_training = filter_tweets.filterTweets('Tweets/noCR_train.txt')\n",
        "print(len(tweets_training))\n",
        "\n",
        "\n",
        "tweets_testing = filter_tweets.filterTweets('Tweets/noCR_test.txt')\n",
        "print(len(tweets_testing))"
      ],
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "10271\n",
            "1145\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}